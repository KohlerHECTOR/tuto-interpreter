{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETER tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install stable-baselines3==2.3\n",
    "%pip install scikit-learn\n",
    "%pip install cloudpickle==3.0.0\n",
    "%pip install joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a PPO and save the final policy on CartPole-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "model = PPO(\"MlpPolicy\", env)\n",
    "model.learn(6e4, progress_bar=True) # 4 minutes on cpu\n",
    "model.save(\"oracle_cartpole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETER DT extraction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from gymnasium import Env\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pickle import dump\n",
    "from statistics import mean\n",
    "from operator import itemgetter\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from typing import Union\n",
    "from stable_baselines3 import PPO, DQN\n",
    "\n",
    "class DecisionTreeExtractor: #Dagger\n",
    "    def __init__(self, model: Union[PPO,DQN], dtpolicy: DecisionTreeClassifier, env: Env, data_per_iter: int=10_000):\n",
    "        self.model = model\n",
    "        self.env = env # is vectorized\n",
    "        self.data_per_iter = data_per_iter\n",
    "        self.dt = dtpolicy\n",
    "        self.deterministic = isinstance(model, DQN)\n",
    "\n",
    "    def collect_data(self):\n",
    "        S, A = [], []\n",
    "        s, _ = self.env.reset()\n",
    "        for i in tqdm(range(self.data_per_iter)):\n",
    "            \n",
    "            action = self.model.predict(s, deterministic=self.deterministic)[0]\n",
    "            S.append(s)\n",
    "            A.append(action)\n",
    "            s, _, term, trunc, _ = self.env.step(action)\n",
    "            if term or trunc:\n",
    "                s, _ = self.env.reset()\n",
    "        return np.array(S), np.array(A)\n",
    "    \n",
    "\n",
    "    def collect_data_dt(self, mask):\n",
    "        S = []\n",
    "        episodes = []\n",
    "        ep_reward = 0\n",
    "        s, _ = self.env.reset()\n",
    "        for i in range(self.data_per_iter):\n",
    "            action = self.dt.predict(s[mask].reshape(1, -1))[0]\n",
    "            S.append(s)\n",
    "            s, r, term, trunc, infos = self.env.step(action)\n",
    "            ep_reward += r\n",
    "            if term or trunc:\n",
    "                s, _ = self.env.reset()\n",
    "                episodes.append(ep_reward)\n",
    "                ep_reward = 0\n",
    "        if len(episodes) < 1:\n",
    "            episodes.append(ep_reward)\n",
    "        return np.array(S), mean(episodes)\n",
    "\n",
    "    def fit_DT(self, S, A):\n",
    "        ## sampling\n",
    "        self.dt.fit(S, A)\n",
    "        acc = self.dt.score(S, A)\n",
    "        return acc\n",
    "\n",
    "    def imitate(self, nb_iter: int, mask):\n",
    "        start_time = time.time()\n",
    "        self.list_acc, self.list_eval, self.list_dt, self.times = [], [], [], []\n",
    "        DS, DA = self.collect_data()\n",
    "        acc_dt = self.fit_DT(DS[:,mask], DA)\n",
    "        S_dt, eval_dt = self.collect_data_dt(mask)\n",
    "        self.times.append(time.time()-start_time)\n",
    "\n",
    "        print(\"Accuracy: {} - Evaluation: {}\".format(acc_dt, eval_dt))\n",
    "        self.list_dt.append(deepcopy(self.dt))\n",
    "        self.list_acc.append(acc_dt)\n",
    "        self.list_eval.append(eval_dt)\n",
    "        DS = np.concatenate((DS, S_dt))\n",
    "        DA = np.concatenate((DA, self.model.predict(S_dt)[0]))\n",
    "        \n",
    "        for _ in range(nb_iter - 1):\n",
    "            acc_dt = self.fit_DT(DS[:,mask], DA)\n",
    "            S_dt, eval_dt = self.collect_data_dt(mask)\n",
    "            self.times.append(time.time()-start_time)\n",
    "\n",
    "            print(\"Accuracy: {} - Evaluation: {}\".format(acc_dt, eval_dt))\n",
    "            self.list_dt.append(deepcopy(self.dt))\n",
    "            self.list_acc.append(acc_dt)\n",
    "            self.list_eval.append(eval_dt)\n",
    "            DS = np.concatenate((DS, S_dt))\n",
    "            DA = np.concatenate((DA, self.model.predict(S_dt)[0]))\n",
    "\n",
    "\n",
    "class ObliqueDecisionTreeExtractor(DecisionTreeExtractor):\n",
    "    def __init__(self, model: Union[PPO,DQN], dtpolicy: DecisionTreeClassifier, env: Env, data_per_iter: int = 10000):\n",
    "        super().__init__(model, dtpolicy, env, data_per_iter)\n",
    "    \n",
    "    def fit_DT(self, S, A):\n",
    "        num_cols = S.shape[1]\n",
    "\n",
    "        # Generate indices for the lower triangular part of the matrix\n",
    "        indices = np.tril_indices(num_cols, k=-1)\n",
    "\n",
    "        # Tile the rows to create matrices for subtraction\n",
    "        a_mat = np.tile(S[:, np.newaxis, :], (1, num_cols, 1))\n",
    "        b_mat = np.transpose(a_mat, axes=(0, 2, 1))\n",
    "\n",
    "        # Compute the differences and store them in the appropriate location in the result array\n",
    "        diffs = a_mat - b_mat\n",
    "        result = diffs[:,  indices[0], indices[1]]\n",
    "\n",
    "        # Stack the original rows with the differences\n",
    "        final = np.hstack((S, result))\n",
    "        return super().fit_DT(final, A)\n",
    "    \n",
    "    def collect_data_dt(self, mask):\n",
    "        S = []\n",
    "        episodes = []\n",
    "        ep_reward = 0\n",
    "        s, _ = self.env.reset()\n",
    "        s_mat = np.tile(s[mask],(s[mask].shape[0],1))\n",
    "        diff_s = s_mat - s_mat.T\n",
    "        s_comb = np.append(s[mask], diff_s[np.tril_indices(s[mask].shape[0], k=-1)])\n",
    "        for h in tqdm(range(self.data_per_iter)):\n",
    "            action = self.dt.predict(s_comb.reshape(1, -1))[0]\n",
    "            S.append(s)\n",
    "            s, r, term, trunc, infos = self.env.step(action)\n",
    "            s_mat = np.tile(s[mask],(s[mask].shape[0],1))\n",
    "            diff_s = s_mat - s_mat.T\n",
    "            s_comb = np.append(s[mask], diff_s[np.tril_indices(s[mask].shape[0], k=-1)])\n",
    "            ep_reward += r\n",
    "            if term or trunc:\n",
    "                s, _ = self.env.reset()\n",
    "                s_mat = np.tile(s[mask],(s[mask].shape[0],1))\n",
    "                diff_s = s_mat - s_mat.T\n",
    "                s_comb = np.append(s[mask], diff_s[np.tril_indices(s[mask].shape[0], k=-1)])\n",
    "                episodes.append(ep_reward)\n",
    "                ep_reward = 0\n",
    "        if len(episodes) < 1:\n",
    "            episodes.append(ep_reward)\n",
    "        return np.array(S), mean(episodes)\n",
    "    \n",
    "    \n",
    "    def save_best_tree(self, save_dir: str):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        for j, tree in enumerate(self.list_dt):\n",
    "            save=open(save_dir+\"Oblique-Tree-{}_{}\".format(j, self.list_eval[j]), 'wb')\n",
    "            dump(tree, save)\n",
    "            \n",
    "        index, element = max(enumerate(self.list_eval), key=itemgetter(1))\n",
    "        self.best_dt = self.list_dt[index]\n",
    "        save=open(save_dir+\"Best-Oblique-Tree-\"+str(element), 'wb')\n",
    "\n",
    "        dump(self.best_dt, save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract an oblique tree imitating the PPO oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import gymnasium as gym\n",
    "\n",
    "# Oblique tree parameters\n",
    "interpretability = dict(max_leaf_nodes=3)\n",
    "clf = DecisionTreeClassifier(**interpretability)\n",
    "\n",
    "# MDP and oracle\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "model = PPO.load(\"oracle_cartpole.zip\")\n",
    "print(\"Reward is {} out of 500\".format(evaluate_policy(model, env)[0]))\n",
    "exp_name = \"trees/\"\n",
    "\n",
    "dagger = ObliqueDecisionTreeExtractor(model, clf, env, data_per_iter=5000)\n",
    "\n",
    "dagger.imitate(nb_iter=10, mask=range(env.observation_space.shape[0]))\n",
    "\n",
    "dagger.save_best_tree(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import joblib\n",
    "import glob\n",
    "\n",
    "clf = joblib.load(glob.glob(\"trees/Best-Oblique-Tree-*\")[0])\n",
    "plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "def convert(interpretable=False):\n",
    "    clf = joblib.load(glob.glob(\"trees/Best-Oblique-Tree-*\")[0])\n",
    "    if interpretable:\n",
    "        feature_names = [\"Cart_Position\", \"Cart_Velocity\", \"Pole_Angle\", \"Pole_Angular_Velocity\"]\n",
    "        actions = [\"left\", \"right\"]\n",
    "    else:\n",
    "        feature_names = [\"[0]\", \"[1]\", \"[2]\", \"[3]\"]\n",
    "        actions = [0, 1]\n",
    "    s = [\"{}\".format(i) for i in np.array(feature_names)]\n",
    "    s_ = [\" - {}\".format(i) for i in np.array(feature_names)]\n",
    "    s = np.array(s)\n",
    "    s_ = np.array(s_)\n",
    "    s_mat = np.tile(s,(s.shape[0],1))\n",
    "    s_mat_ = np.tile(s_,(s_.shape[0],1))\n",
    "    # pint(s_mat_)\n",
    "\n",
    "    diff_s = []\n",
    "    for m in range(s_mat.shape[0]):\n",
    "        level = []\n",
    "        for j in range(s_mat.shape[1]):\n",
    "            level.append(s_mat[m,j] + s_mat_[j,m])\n",
    "        diff_s.append(level)\n",
    "\n",
    "    diff_s = np.array(diff_s, dtype=np.str_)\n",
    "\n",
    "    s_comb = np.append(s, diff_s[np.tril_indices(s.shape[0], k=-1)])\n",
    "\n",
    "\n",
    "    r = tree.export_text(clf, feature_names=s_comb, class_names=actions)\n",
    "    if interpretable:\n",
    "        if not os.path.exists('play_cartpole_interpretable.py'):\n",
    "            with open('play_cartpole_interpretable.py', 'a') as the_file:\n",
    "                the_file.write('def play(state):\\n')\n",
    "                for line in r.split(\"\\n\")[:-1]:\n",
    "                    split_indent = line.split(\"|\")\n",
    "                    nb_indent = 2 * (len(split_indent)-2 + 1) #first empty last is if else + 1for def\n",
    "                    features_sign_val = split_indent[-1].split('--- ')[1]\n",
    "                    if \"<=\" in features_sign_val:\n",
    "                        each_feat_val = features_sign_val.split(\"<=\")\n",
    "\n",
    "                        featss = each_feat_val[0]\n",
    "                        if \"-\" in featss :\n",
    "                            each_feat = each_feat_val[0].split(\" - \")\n",
    "                            val = each_feat_val[1]\n",
    "\n",
    "                            python_line = nb_indent * \"  \" + \"if state.\" + each_feat[0] +\" - \" + \"state.\" + each_feat[1] + \" <=\" + val +\":\\n\"\n",
    "                        else:\n",
    "                            python_line = nb_indent * \"  \" + \"if state.\" + features_sign_val+\":\\n\"\n",
    "                    elif \">\" in features_sign_val:\n",
    "                        python_line = nb_indent * \"  \" + \"else:\\n\"\n",
    "                    else:\n",
    "                        python_line = nb_indent * \"  \" + \"return \\\"\" + features_sign_val.split(\"class: \")[1] + \"\\\"\\n\"\n",
    "                    the_file.write(python_line)\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists('play_cartpole_playable.py'):\n",
    "            \n",
    "            with open('play_cartpole_playable.py', 'a') as the_file:\n",
    "                the_file.write('def play(state):\\n')\n",
    "                for line in r.split(\"\\n\")[:-1]:\n",
    "                    split_indent = line.split(\"|\")\n",
    "                    nb_indent = 2 * (len(split_indent)-2 + 1) #first empty last is if else + 1for def\n",
    "                    features_sign_val = split_indent[-1].split('--- ')[1]\n",
    "                    if \"<=\" in features_sign_val:\n",
    "                        each_feat_val = features_sign_val.split(\"<=\")\n",
    "\n",
    "                        featss = each_feat_val[0]\n",
    "                        if \"-\" in featss :\n",
    "                            each_feat = each_feat_val[0].split(\" - \")\n",
    "                            val = each_feat_val[1]\n",
    "\n",
    "                            python_line = nb_indent * \"  \" + \"if state\" + each_feat[0] +\" - \" + \"state\" + each_feat[1] + \" <=\" + val +\":\\n\"\n",
    "                        else:\n",
    "                            python_line = nb_indent * \"  \" + \"if state\" + features_sign_val+\":\\n\"\n",
    "                    elif \">\" in features_sign_val:\n",
    "                        python_line = nb_indent * \"  \" + \"else:\\n\"\n",
    "                    else:\n",
    "                        python_line = nb_indent * \"  \" + \"return \" + features_sign_val.split(\"class: \")[1] + \"\\n\"\n",
    "                    the_file.write(python_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpretable program\n",
    "convert(True)\n",
    "#playable_program\n",
    "convert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from play_cartpole_playable import play\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "s, _ = env.reset()\n",
    "done = False\n",
    "sum_r = 0\n",
    "while not done:\n",
    "    a = play(s)\n",
    "    s, r, term, trunc, _ = env.step(a)\n",
    "    env.render()\n",
    "    sum_r += r\n",
    "    done = term or trunc\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
